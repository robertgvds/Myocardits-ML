{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8733110,"sourceType":"datasetVersion","datasetId":5242137},{"sourceId":8740562,"sourceType":"datasetVersion","datasetId":5242143,"isSourceIdPinned":true}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/robertgvds/treinamento-myocarditis?scriptVersionId=185608883\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# TREINAMENTO USANDO A REDE INICIAL CATEGORICA USANDO CONV2 COM DADOS EM ARRAYS","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-06-25T21:51:29.990876Z","iopub.execute_input":"2024-06-25T21:51:29.991603Z","iopub.status.idle":"2024-06-25T21:51:31.038523Z","shell.execute_reply.started":"2024-06-25T21:51:29.991564Z","shell.execute_reply":"2024-06-25T21:51:31.037628Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Tue Jun 25 21:51:30 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   44C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   46C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ['TF_DISABLE_JIT'] = '1'","metadata":{"execution":{"iopub.status.busy":"2024-06-25T21:51:31.041075Z","iopub.execute_input":"2024-06-25T21:51:31.041467Z","iopub.status.idle":"2024-06-25T21:51:31.04674Z","shell.execute_reply.started":"2024-06-25T21:51:31.041428Z","shell.execute_reply":"2024-06-25T21:51:31.045785Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!jupyter notebook --NotebookApp.iopub_msg_rate_limit=1.0e10","metadata":{"execution":{"iopub.status.busy":"2024-06-25T21:51:31.047712Z","iopub.execute_input":"2024-06-25T21:51:31.048023Z","iopub.status.idle":"2024-06-25T21:51:36.462639Z","shell.execute_reply.started":"2024-06-25T21:51:31.047993Z","shell.execute_reply":"2024-06-25T21:51:36.461539Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[32m[I 21:51:33.448 NotebookApp]\u001b[m [nb_conda_kernels] enabled, 1 kernels found\n\n  _   _          _      _\n | | | |_ __  __| |__ _| |_ ___\n | |_| | '_ \\/ _` / _` |  _/ -_)\n  \\___/| .__/\\__,_\\__,_|\\__\\___|\n       |_|\n                       \nRead the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions.\n\nhttps://jupyter-notebook.readthedocs.io/en/latest/migrate_to_notebook7.html\n\nPlease note that updating to Notebook 7 might break some of your extensions.\n\n\u001b[32m[I 21:51:33.767 NotebookApp]\u001b[m Registered dataproc_jupyter_plugin server extension\njupyter_http_over_ws extension initialized. Listening on /http_over_websocket\n\u001b[32m[I 21:51:34.038 NotebookApp]\u001b[m Skipped non-installed server(s): bash-language-server, dockerfile-language-server-nodejs, javascript-typescript-langserver, jedi-language-server, julia-language-server, pyright, python-language-server, r-languageserver, sql-language-server, texlab, typescript-language-server, unified-language-server, vscode-css-languageserver-bin, vscode-html-languageserver-bin, vscode-json-languageserver-bin, yaml-language-server\n\u001b[32m[I 21:51:34.446 NotebookApp]\u001b[m [Jupytext Server Extension] Deriving a JupytextContentsManager from LargeFileManager\n\u001b[32m[I 21:51:34.712 NotebookApp]\u001b[m [nb_conda] enabled\n\u001b[35m[C 21:51:34.773 NotebookApp]\u001b[m You must use Jupyter Server v1 to load nbdime as a classic notebook server extension. You have v2.12.5 installed.\n    You can fix this by executing:\n        pip install -U \"jupyter-server<2.0.0\"\n\u001b[35m[C 21:51:36.056 NotebookApp]\u001b[m Running as root is not recommended. Use --allow-root to bypass.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Bibliotecas e Constantes","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow[and-cuda]","metadata":{"execution":{"iopub.status.busy":"2024-06-25T21:51:36.463959Z","iopub.execute_input":"2024-06-25T21:51:36.464235Z","iopub.status.idle":"2024-06-25T21:55:35.95178Z","shell.execute_reply.started":"2024-06-25T21:51:36.464208Z","shell.execute_reply":"2024-06-25T21:55:35.950889Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow[and-cuda] in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (1.59.3)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow[and-cuda])\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting nvidia-cublas-cu12==12.2.5.6 (from tensorflow[and-cuda])\n  Downloading nvidia_cublas_cu12-12.2.5.6-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.2.142 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_cupti_cu12-12.2.142-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-nvcc-cu12==12.2.140 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_nvcc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.2.140 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_nvrtc_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.2.140 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_runtime_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cudnn-cu12==8.9.4.25 (from tensorflow[and-cuda])\n  Downloading nvidia_cudnn_cu12-8.9.4.25-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu12==11.0.8.103 (from tensorflow[and-cuda])\n  Downloading nvidia_cufft_cu12-11.0.8.103-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.3.141 (from tensorflow[and-cuda])\n  Downloading nvidia_curand_cu12-10.3.3.141-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.5.2.141 (from tensorflow[and-cuda])\n  Downloading nvidia_cusolver_cu12-11.5.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.2.141 (from tensorflow[and-cuda])\n  Downloading nvidia_cusparse_cu12-12.1.2.141-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.16.5 (from tensorflow[and-cuda])\n  Downloading nvidia_nccl_cu12-2.16.5-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.2.140 (from tensorflow[and-cuda])\n  Downloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting tensorrt==8.6.1.post1 (from tensorflow[and-cuda])\n  Downloading tensorrt-8.6.1.post1.tar.gz (18 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tensorrt-bindings==8.6.1 (from tensorflow[and-cuda])\n  Downloading tensorrt_bindings-8.6.1-cp310-none-manylinux_2_17_x86_64.whl.metadata (621 bytes)\nINFO: pip is looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\nCollecting tensorflow[and-cuda]\n  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nCollecting ml-dtypes~=0.3.1 (from tensorflow[and-cuda])\n  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (2.32.3)\nCollecting tensorboard<2.17,>=2.16 (from tensorflow[and-cuda])\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow[and-cuda]) (3.3.3)\nCollecting nvidia-cublas-cu12==12.3.4.1 (from tensorflow[and-cuda])\n  Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.3.101 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-nvcc-cu12==12.3.107 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.3.107 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.3.101 (from tensorflow[and-cuda])\n  Downloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cudnn-cu12==8.9.7.29 (from tensorflow[and-cuda])\n  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu12==11.0.12.1 (from tensorflow[and-cuda])\n  Downloading nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.4.107 (from tensorflow[and-cuda])\n  Downloading nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.5.4.101 (from tensorflow[and-cuda])\n  Downloading nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.2.0.103 (from tensorflow[and-cuda])\n  Downloading nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from tensorflow[and-cuda])\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.3.101 (from tensorflow[and-cuda])\n  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.42.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow[and-cuda]) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow[and-cuda]) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow[and-cuda]) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2024.2.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow[and-cuda]) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow[and-cuda]) (2.1.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow[and-cuda]) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow[and-cuda]) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow[and-cuda]) (0.1.2)\nDownloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl (412.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.6/412.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (14.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (22.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-manylinux1_x86_64.whl (24.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (867 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.7/704.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl (98.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl (125.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl (197.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.5/197.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, tensorboard, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.2.0\n    Uninstalling ml-dtypes-0.2.0:\n      Successfully uninstalled ml-dtypes-0.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.16.1 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.16.1 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ml-dtypes-0.3.2 nvidia-cublas-cu12-12.3.4.1 nvidia-cuda-cupti-cu12-12.3.101 nvidia-cuda-nvcc-cu12-12.3.107 nvidia-cuda-nvrtc-cu12-12.3.107 nvidia-cuda-runtime-cu12-12.3.101 nvidia-cudnn-cu12-8.9.7.29 nvidia-cufft-cu12-11.0.12.1 nvidia-curand-cu12-10.3.4.107 nvidia-cusolver-cu12-11.5.4.101 nvidia-cusparse-cu12-12.2.0.103 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 tensorboard-2.16.2 tensorflow-2.16.1\n","output_type":"stream"}]},{"cell_type":"code","source":"#------------------------------------------------------------------------------\n# BIBLIOTECAS\n\nimport os\nimport numpy as np\nfrom PIL import Image\nimport sys\nimport random\n\n# BIBLIOTECAS DEEP LEARNING\nimport datetime\nimport tensorflow as tf\nfrom sklearn.metrics import auc, classification_report, confusion_matrix, roc_curve\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import CSVLogger\n\n#------------------------------------------------------------------------------\n# CONSTANTES\n\nDATASET_TYPE = ['cleaned', 'selected']\nDATASET_TYPE = DATASET_TYPE[0] # Dataset utilizado no treinamento\n\nSEED = 10\nnp.random.seed(SEED) # semente geradora dos numeros aleatorios\nrandom.seed(SEED)\ntf.random.set_seed(SEED)\n\nN_FOLDS = 5\nN_EPOCHS = 30\nBATCH_SIZE = (32 if DATASET_TYPE == 'selected' else 512)\nTARGET_SIZE = (100, 100)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T21:55:35.954284Z","iopub.execute_input":"2024-06-25T21:55:35.954583Z","iopub.status.idle":"2024-06-25T21:55:42.670632Z","shell.execute_reply.started":"2024-06-25T21:55:35.954553Z","shell.execute_reply":"2024-06-25T21:55:42.669667Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Diretórios e Carregamentos de Dados","metadata":{}},{"cell_type":"code","source":"# Criando pasta de resultados\nif not os.path.exists(f'{DATASET_TYPE}'):\n    os.mkdir(f'{DATASET_TYPE}')","metadata":{"execution":{"iopub.status.busy":"2024-06-25T21:55:42.671731Z","iopub.execute_input":"2024-06-25T21:55:42.672232Z","iopub.status.idle":"2024-06-25T21:55:42.67765Z","shell.execute_reply.started":"2024-06-25T21:55:42.672207Z","shell.execute_reply":"2024-06-25T21:55:42.676784Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#------------------------------------------------------------------------------\n# DIRETÓRIOS DOS DATASETS\n\nDATASET_PATH = f'/kaggle/input/myocardits-dataset-{DATASET_TYPE}'\nRESULTS_PATH = f'/kaggle/working/{DATASET_TYPE}'\n\nNORMAL_PATH = DATASET_PATH + '/Normal/'\nSICK_PATH = DATASET_PATH + '/Sick/'\n\n# Diretorios de cada Individuo:\nnormal_datasets = [f'{NORMAL_PATH}Individuo_{i:02}/' for i in range(1, 17)]\nsick_datasets = [f'{SICK_PATH}Individuo_{i:02}/' for i in range(1, 32)]\n\nprint(normal_datasets)\nprint(sick_datasets)\n\nNORMAL_SPLITS = [[9, 10, 12, 15],\n                 [1,8,11],\n                 [4,5,14],\n                 [2,7,13],\n                 [3,6,16]]\n\nSICK_SPLITS = [[21,23,26,27,36,38],\n               [18,37,39,40,41,45,46],\n               [20,24,28,29,31,32],\n               [19,22,30,33,42,47],\n               [17,25,34,35,43,44]]\n\nnormal_splits = [[],[],[],[],[]]\nsick_splits = [[],[],[],[],[]]\n\nfor split in range(N_FOLDS):\n    normal_splits[split].extend(normal_datasets[i-1] for i in NORMAL_SPLITS[split])\n    sick_splits[split].extend(sick_datasets[i-17] for i in SICK_SPLITS[split])","metadata":{"execution":{"iopub.status.busy":"2024-06-25T21:55:42.678627Z","iopub.execute_input":"2024-06-25T21:55:42.678923Z","iopub.status.idle":"2024-06-25T21:55:42.69017Z","shell.execute_reply.started":"2024-06-25T21:55:42.6789Z","shell.execute_reply":"2024-06-25T21:55:42.689219Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"['/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_01/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_02/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_03/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_04/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_05/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_06/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_07/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_08/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_09/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_10/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_11/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_12/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_13/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_14/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_15/', '/kaggle/input/myocardits-dataset-cleaned/Normal/Individuo_16/']\n['/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_01/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_02/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_03/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_04/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_05/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_06/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_07/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_08/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_09/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_10/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_11/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_12/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_13/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_14/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_15/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_16/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_17/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_18/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_19/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_20/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_21/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_22/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_23/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_24/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_25/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_26/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_27/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_28/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_29/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_30/', '/kaggle/input/myocardits-dataset-cleaned/Sick/Individuo_31/']\n","output_type":"stream"}]},{"cell_type":"code","source":"#------------------------------------------------------------------------------\n# CARREGAMENTO DE DADOS\n\nprint('\\nIniciando carregamento e processamento das imagens..............!')\n\ndef carregar_imagens(diretorio):\n    global num_imagens\n    imagens = []\n    for pasta_atual, subpastas, arquivos in os.walk(diretorio):\n        for arquivo in arquivos:\n            if arquivo.endswith(('.jpg', '.jpeg', '.png')):\n                caminho = os.path.join(pasta_atual, arquivo)\n                \n                img = Image.open(caminho)\n                img = img.resize(TARGET_SIZE)\n                img_array = np.array(img)\n                imagens.append(img_array)\n                \n                num_imagens += 1\n                sys.stdout.write(\"\\rNumero de imagens carregados: %i\" % num_imagens)\n                sys.stdout.flush()\n                \n    return imagens\n\nnum_imagens = 0\n\nprint('\\nPacientes normais:')\nnormal_groups = []\nfor diretorios in normal_splits:\n    imagens = []\n    for individuos in diretorios:\n        imagens.extend(carregar_imagens(individuos))\n    normal_groups.append(imagens)\n\nnum_imagens = 0\n\nprint('\\n\\nPacientes doentes:')\nsick_groups = []\nfor diretorios in sick_splits:\n    imagens = []\n    for individuos in diretorios:\n        imagens.extend(carregar_imagens(individuos))\n    sick_groups.append(imagens)\n\n# DATASETS SEPRADAOS EM 5 PARA VALIDAÇÃO CRUZADA    \nx_data = [[],[],[],[],[]]\ny_data = [[],[],[],[],[]]\n\nprint('\\n\\nNumero de imagens por split:')\nfor i in range(N_FOLDS):\n    x_data[i].extend(path for path in normal_groups[i])\n    y_data[i].extend([1, 0] for path in normal_groups[i])\n    x_data[i].extend(path for path in sick_groups[i])\n    y_data[i].extend([0, 1] for path in sick_groups[i])\n    print(f'Split {i+1}: {len(x_data[i])} imagens ({len(normal_groups[i])} saudáveis e {len(sick_groups[i])} doentes).')","metadata":{"execution":{"iopub.status.busy":"2024-06-25T21:55:42.691147Z","iopub.execute_input":"2024-06-25T21:55:42.691409Z","iopub.status.idle":"2024-06-25T22:00:59.112977Z","shell.execute_reply.started":"2024-06-25T21:55:42.691386Z","shell.execute_reply":"2024-06-25T22:00:59.112106Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\nIniciando carregamento e processamento das imagens..............!\n\nPacientes normais:\nNumero de imagens carregados: 34020\n\nPacientes doentes:\nNumero de imagens carregados: 53316\n\nNumero de imagens por split:\nSplit 1: 17433 imagens (6719 saudáveis e 10714 doentes).\nSplit 2: 17452 imagens (6746 saudáveis e 10706 doentes).\nSplit 3: 17459 imagens (6795 saudáveis e 10664 doentes).\nSplit 4: 17502 imagens (6875 saudáveis e 10627 doentes).\nSplit 5: 17490 imagens (6885 saudáveis e 10605 doentes).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Treinamento","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Arquitetura CNN\ndef cnn_model(input_shape, num_classes):\n    model=Sequential()\n    model.add(Conv2D(32,3,padding='same',activation='relu',strides=2,input_shape=input_shape))\n    model.add(Conv2D(64,3,padding='same',activation='relu',strides=2))\n    model.add(Conv2D(128,3,padding='same',activation='relu',strides=2))\n    model.add(Conv2D(256,3,padding='same',activation='relu',strides=1))\n    model.add(Conv2D(256,3,padding='same',activation='relu',strides=1))\n    model.add(Conv2D(256,3,padding='same',activation='relu',strides=1))\n    model.add(Flatten())\n    model.add(Dense(256,activation='relu'))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dense(64,activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes,activation='softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-25T22:00:59.114289Z","iopub.execute_input":"2024-06-25T22:00:59.115Z","iopub.status.idle":"2024-06-25T22:00:59.1233Z","shell.execute_reply.started":"2024-06-25T22:00:59.114964Z","shell.execute_reply":"2024-06-25T22:00:59.122284Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#------------------------------------------------------------------------------\n# SEPARAÇÃO DE DADOS E TREINAMENTO\n\nlst_accuracy=[]\nlst_acc=[]\nlst_loss=[]\nlst_reports=[]\nlst_AUC=[]\nlst_matrix=[]\nlst_times=[]\nlst_history=[]\n\n#------------------------------------------------------------------------------\n# TREINAMENTO POR FOLDS\n\nfor fold in range(N_FOLDS):\n\n    print(f'\\n\\nFOLD {fold+1}:')\n\n    #--------------------------------------------------------------------------\n    # CARREGAMENTO DAS IMAGENS DE TREINAMENTO, VALIDACAO E TESTE\n\n    print(f'\\nCarregamento das imagens do fold {fold+1} para treinamento.............!')\n\n    folds = [0, 1, 2, 3, 4]\n\n    x_test = np.array(x_data[fold])\n    y_test = np.array(y_data[fold])\n    folds.remove(fold)\n\n    x_valid = np.array(x_data[folds[0]])\n    y_valid = np.array(y_data[folds[0]])\n    folds.remove(folds[0])\n\n    x_train, y_train = [], []\n    for i in folds:\n        x_train.extend(x_data[i])\n        y_train.extend(y_data[i])\n    x_train = np.array(x_train)\n    y_train = np.array(y_train)\n\n    print(f'Numero de imagens no treinamento: {len(x_train)} imagens.')\n    print(f'Numero de imagens na validação: {len(x_valid)} imagens.')\n    print(f'Numero de imagens no teste: {len(x_test)} imagens.')\n\n    #--------------------------------------------------------------------------\n    # ARQUITETURA E COMPILACAO\n\n    model=cnn_model((100, 100, 1), 2)\n    \n    # Compilacao do modelo\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n\n    #--------------------------------------------------------------------------\n    # TREINAMENTO\n    print('\\nIniciando o treinamento.........................................!\\n')\n\n    calback=CSVLogger(RESULTS_PATH + f'/logger_fold{fold+1}.log')\n\n    # Treinando o modelo\n    start=datetime.datetime.now()\n\n    history=model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS, validation_data=(x_valid, y_valid), callbacks=[calback])\n\n    end=datetime.datetime.now()\n    training_time=end-start\n\n    # Salvamento do modelo\n    model.save(RESULTS_PATH + f'/{DATASET_TYPE}-CNN-{fold+1}.h5')\n\n    #--------------------------------------------------------------------------\n    # TESTE\n\n    # Testando o modelo\n    print(\"\\nTestando imagens................................................!\\n\")\n\n    # Acuracia e Perda do Teste\n    test_loss, test_acc = model.evaluate(x_test, y_test)\n\n    print(model.metrics_names)\n\n    #--------------------------------------------------------------------------\n    # ARMAZENAMENTO DOS INFORMACOES\n\n    # Fazendo previsões\n    predicts = model.predict(x_test)\n    predicts = predicts.argmax(axis=1)\n\n    # Obtendo os rótulos verdadeiros\n    actuals=y_test.argmax(axis=1)\n\n    # Calculando a curva ROC\n    fpr, tpr, _ = roc_curve(actuals, predicts, pos_label=1)\n    a = auc(fpr, tpr)\n\n    # Gerando o relatório de classificação\n    r = classification_report(actuals, predicts, zero_division=1)\n\n    # Calculando a matriz de confusão\n    c = confusion_matrix(actuals, predicts)\n    accuracy = np.trace(c)/np.sum(c)\n\n    lst_history.append(history)\n    lst_times.append(training_time)\n    lst_accuracy.append(accuracy)\n    lst_acc.append(test_acc)\n    lst_loss.append(test_loss)\n    lst_AUC.append(a)\n    lst_reports.append(r)\n    lst_matrix.append(c)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T22:00:59.124671Z","iopub.execute_input":"2024-06-25T22:00:59.124959Z","iopub.status.idle":"2024-06-25T22:47:29.818548Z","shell.execute_reply.started":"2024-06-25T22:00:59.124935Z","shell.execute_reply":"2024-06-25T22:47:29.817574Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\n\nFOLD 1:\n\nCarregamento das imagens do fold 1 para treinamento.............!\nNumero de imagens no treinamento: 52451 imagens.\nNumero de imagens na validação: 17452 imagens.\nNumero de imagens no teste: 17433 imagens.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\nIniciando o treinamento.........................................!\n\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1719352864.160171     130 service.cc:145] XLA service 0x7a7af0007390 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1719352864.160232     130 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1719352864.160240     130 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/103\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:21\u001b[0m 17s/step - categorical_accuracy: 0.5273 - loss: 1.0415","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1719352878.190665     130 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 258ms/step - categorical_accuracy: 0.6386 - loss: 1.0853 - val_categorical_accuracy: 0.5706 - val_loss: 1.0607\nEpoch 2/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 159ms/step - categorical_accuracy: 0.9410 - loss: 0.1633 - val_categorical_accuracy: 0.5817 - val_loss: 2.0205\nEpoch 3/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 163ms/step - categorical_accuracy: 0.9733 - loss: 0.0710 - val_categorical_accuracy: 0.5819 - val_loss: 2.1057\nEpoch 4/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 167ms/step - categorical_accuracy: 0.9842 - loss: 0.0432 - val_categorical_accuracy: 0.5717 - val_loss: 1.9899\nEpoch 5/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 170ms/step - categorical_accuracy: 0.9886 - loss: 0.0311 - val_categorical_accuracy: 0.5618 - val_loss: 3.4448\nEpoch 6/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 175ms/step - categorical_accuracy: 0.9926 - loss: 0.0203 - val_categorical_accuracy: 0.5916 - val_loss: 3.4631\nEpoch 7/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 178ms/step - categorical_accuracy: 0.9946 - loss: 0.0150 - val_categorical_accuracy: 0.5697 - val_loss: 4.2726\nEpoch 8/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9955 - loss: 0.0143 - val_categorical_accuracy: 0.5750 - val_loss: 3.8473\nEpoch 9/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9959 - loss: 0.0141 - val_categorical_accuracy: 0.5912 - val_loss: 4.0750\nEpoch 10/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9969 - loss: 0.0109 - val_categorical_accuracy: 0.5708 - val_loss: 5.9317\nEpoch 11/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9984 - loss: 0.0072 - val_categorical_accuracy: 0.5512 - val_loss: 4.6572\nEpoch 12/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9971 - loss: 0.0101 - val_categorical_accuracy: 0.5615 - val_loss: 3.8720\nEpoch 13/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9975 - loss: 0.0084 - val_categorical_accuracy: 0.5956 - val_loss: 6.0474\nEpoch 14/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9982 - loss: 0.0066 - val_categorical_accuracy: 0.5700 - val_loss: 5.3737\nEpoch 15/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9985 - loss: 0.0051 - val_categorical_accuracy: 0.6001 - val_loss: 5.2679\nEpoch 16/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9968 - loss: 0.0108 - val_categorical_accuracy: 0.5839 - val_loss: 6.1751\nEpoch 17/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9975 - loss: 0.0086 - val_categorical_accuracy: 0.5931 - val_loss: 6.3558\nEpoch 18/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9985 - loss: 0.0057 - val_categorical_accuracy: 0.5619 - val_loss: 5.0374\nEpoch 19/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9987 - loss: 0.0054 - val_categorical_accuracy: 0.5856 - val_loss: 6.1751\nEpoch 20/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9985 - loss: 0.0045 - val_categorical_accuracy: 0.6022 - val_loss: 5.8260\nEpoch 21/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9990 - loss: 0.0039 - val_categorical_accuracy: 0.5887 - val_loss: 6.6171\nEpoch 22/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9986 - loss: 0.0053 - val_categorical_accuracy: 0.5588 - val_loss: 6.2713\nEpoch 23/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9990 - loss: 0.0029 - val_categorical_accuracy: 0.5599 - val_loss: 5.4500\nEpoch 24/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9988 - loss: 0.0045 - val_categorical_accuracy: 0.6045 - val_loss: 4.1966\nEpoch 25/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9987 - loss: 0.0063 - val_categorical_accuracy: 0.5596 - val_loss: 6.3737\nEpoch 26/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9984 - loss: 0.0050 - val_categorical_accuracy: 0.5681 - val_loss: 6.0840\nEpoch 27/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9989 - loss: 0.0041 - val_categorical_accuracy: 0.5763 - val_loss: 7.2536\nEpoch 28/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9983 - loss: 0.0073 - val_categorical_accuracy: 0.5908 - val_loss: 6.8353\nEpoch 29/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9990 - loss: 0.0028 - val_categorical_accuracy: 0.5741 - val_loss: 8.2098\nEpoch 30/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9996 - loss: 0.0035 - val_categorical_accuracy: 0.5684 - val_loss: 7.1052\n\nTestando imagens................................................!\n\n\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - categorical_accuracy: 0.4201 - loss: 10.5454\n['loss', 'compile_metrics']\n\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n\n\nFOLD 2:\n\nCarregamento das imagens do fold 2 para treinamento.............!\nNumero de imagens no treinamento: 52451 imagens.\nNumero de imagens na validação: 17433 imagens.\nNumero de imagens no teste: 17452 imagens.\n\nIniciando o treinamento.........................................!\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 203ms/step - categorical_accuracy: 0.6660 - loss: 0.9769 - val_categorical_accuracy: 0.5987 - val_loss: 1.3750\nEpoch 2/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 177ms/step - categorical_accuracy: 0.9471 - loss: 0.1371 - val_categorical_accuracy: 0.6001 - val_loss: 2.0419\nEpoch 3/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 176ms/step - categorical_accuracy: 0.9772 - loss: 0.0639 - val_categorical_accuracy: 0.6033 - val_loss: 2.6202\nEpoch 4/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9859 - loss: 0.0394 - val_categorical_accuracy: 0.5861 - val_loss: 3.5870\nEpoch 5/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9917 - loss: 0.0259 - val_categorical_accuracy: 0.6096 - val_loss: 3.8663\nEpoch 6/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9938 - loss: 0.0186 - val_categorical_accuracy: 0.6122 - val_loss: 3.6910\nEpoch 7/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9957 - loss: 0.0121 - val_categorical_accuracy: 0.6109 - val_loss: 4.3062\nEpoch 8/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9972 - loss: 0.0094 - val_categorical_accuracy: 0.6252 - val_loss: 3.7121\nEpoch 9/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9969 - loss: 0.0103 - val_categorical_accuracy: 0.6232 - val_loss: 4.0907\nEpoch 10/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9977 - loss: 0.0084 - val_categorical_accuracy: 0.5794 - val_loss: 7.2364\nEpoch 11/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9968 - loss: 0.0136 - val_categorical_accuracy: 0.6282 - val_loss: 4.8710\nEpoch 12/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9981 - loss: 0.0063 - val_categorical_accuracy: 0.6079 - val_loss: 6.0079\nEpoch 13/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9989 - loss: 0.0037 - val_categorical_accuracy: 0.6176 - val_loss: 5.9980\nEpoch 14/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9978 - loss: 0.0085 - val_categorical_accuracy: 0.6179 - val_loss: 3.7015\nEpoch 15/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9991 - loss: 0.0044 - val_categorical_accuracy: 0.6161 - val_loss: 4.7689\nEpoch 16/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9986 - loss: 0.0054 - val_categorical_accuracy: 0.6048 - val_loss: 7.3355\nEpoch 17/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9980 - loss: 0.0069 - val_categorical_accuracy: 0.6472 - val_loss: 5.5210\nEpoch 18/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9993 - loss: 0.0033 - val_categorical_accuracy: 0.6226 - val_loss: 6.4332\nEpoch 19/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9990 - loss: 0.0032 - val_categorical_accuracy: 0.6281 - val_loss: 6.9007\nEpoch 20/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9989 - loss: 0.0036 - val_categorical_accuracy: 0.6118 - val_loss: 7.4947\nEpoch 21/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9988 - loss: 0.0060 - val_categorical_accuracy: 0.6327 - val_loss: 7.0326\nEpoch 22/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9985 - loss: 0.0068 - val_categorical_accuracy: 0.6088 - val_loss: 7.6693\nEpoch 23/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9991 - loss: 0.0039 - val_categorical_accuracy: 0.6374 - val_loss: 10.8049\nEpoch 24/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9985 - loss: 0.0059 - val_categorical_accuracy: 0.6135 - val_loss: 8.6699\nEpoch 25/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9991 - loss: 0.0029 - val_categorical_accuracy: 0.6343 - val_loss: 7.9037\nEpoch 26/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9986 - loss: 0.0048 - val_categorical_accuracy: 0.6363 - val_loss: 7.7625\nEpoch 27/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9996 - loss: 0.0017 - val_categorical_accuracy: 0.6133 - val_loss: 9.8192\nEpoch 28/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9998 - loss: 0.0012 - val_categorical_accuracy: 0.6169 - val_loss: 10.7097\nEpoch 29/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9999 - loss: 2.7379e-04 - val_categorical_accuracy: 0.6157 - val_loss: 11.8686\nEpoch 30/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9987 - loss: 0.0070 - val_categorical_accuracy: 0.6040 - val_loss: 7.0066\n\nTestando imagens................................................!\n\n\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - categorical_accuracy: 0.4249 - loss: 8.0982\n['loss', 'compile_metrics']\n\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n\n\nFOLD 3:\n\nCarregamento das imagens do fold 3 para treinamento.............!\nNumero de imagens no treinamento: 52444 imagens.\nNumero de imagens na validação: 17433 imagens.\nNumero de imagens no teste: 17459 imagens.\n\nIniciando o treinamento.........................................!\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 271ms/step - categorical_accuracy: 0.6527 - loss: 0.9790 - val_categorical_accuracy: 0.5667 - val_loss: 1.4018\nEpoch 2/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 176ms/step - categorical_accuracy: 0.9421 - loss: 0.1537 - val_categorical_accuracy: 0.6021 - val_loss: 1.9165\nEpoch 3/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 175ms/step - categorical_accuracy: 0.9737 - loss: 0.0708 - val_categorical_accuracy: 0.5940 - val_loss: 2.6263\nEpoch 4/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9855 - loss: 0.0411 - val_categorical_accuracy: 0.5580 - val_loss: 3.1847\nEpoch 5/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9910 - loss: 0.0282 - val_categorical_accuracy: 0.5716 - val_loss: 4.4873\nEpoch 6/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9909 - loss: 0.0261 - val_categorical_accuracy: 0.5908 - val_loss: 3.2844\nEpoch 7/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9934 - loss: 0.0196 - val_categorical_accuracy: 0.5999 - val_loss: 3.2588\nEpoch 8/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9963 - loss: 0.0116 - val_categorical_accuracy: 0.6080 - val_loss: 3.9312\nEpoch 9/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9962 - loss: 0.0111 - val_categorical_accuracy: 0.5805 - val_loss: 3.9260\nEpoch 10/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9975 - loss: 0.0092 - val_categorical_accuracy: 0.6239 - val_loss: 4.7026\nEpoch 11/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9955 - loss: 0.0128 - val_categorical_accuracy: 0.6188 - val_loss: 5.3419\nEpoch 12/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9982 - loss: 0.0063 - val_categorical_accuracy: 0.5862 - val_loss: 6.1979\nEpoch 13/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9979 - loss: 0.0080 - val_categorical_accuracy: 0.6070 - val_loss: 5.9062\nEpoch 14/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9975 - loss: 0.0098 - val_categorical_accuracy: 0.5959 - val_loss: 5.0314\nEpoch 15/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9968 - loss: 0.0117 - val_categorical_accuracy: 0.5782 - val_loss: 4.8618\nEpoch 16/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9986 - loss: 0.0041 - val_categorical_accuracy: 0.6491 - val_loss: 4.8123\nEpoch 17/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9983 - loss: 0.0054 - val_categorical_accuracy: 0.5896 - val_loss: 4.0272\nEpoch 18/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9990 - loss: 0.0036 - val_categorical_accuracy: 0.6024 - val_loss: 6.3379\nEpoch 19/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9995 - loss: 0.0019 - val_categorical_accuracy: 0.5819 - val_loss: 6.5944\nEpoch 20/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9978 - loss: 0.0071 - val_categorical_accuracy: 0.6095 - val_loss: 4.4086\nEpoch 21/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9984 - loss: 0.0058 - val_categorical_accuracy: 0.6110 - val_loss: 5.8379\nEpoch 22/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9990 - loss: 0.0043 - val_categorical_accuracy: 0.5970 - val_loss: 6.1721\nEpoch 23/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9992 - loss: 0.0023 - val_categorical_accuracy: 0.6087 - val_loss: 7.8732\nEpoch 24/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9986 - loss: 0.0044 - val_categorical_accuracy: 0.6002 - val_loss: 7.3047\nEpoch 25/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9986 - loss: 0.0054 - val_categorical_accuracy: 0.5918 - val_loss: 9.6305\nEpoch 26/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9994 - loss: 0.0023 - val_categorical_accuracy: 0.5924 - val_loss: 6.2884\nEpoch 27/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9986 - loss: 0.0046 - val_categorical_accuracy: 0.5779 - val_loss: 7.9675\nEpoch 28/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9996 - loss: 0.0034 - val_categorical_accuracy: 0.6076 - val_loss: 5.9651\nEpoch 29/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9990 - loss: 0.0038 - val_categorical_accuracy: 0.5892 - val_loss: 7.6633\nEpoch 30/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9994 - loss: 0.0015 - val_categorical_accuracy: 0.5402 - val_loss: 10.2138\n\nTestando imagens................................................!\n\n\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - categorical_accuracy: 0.5345 - loss: 10.7289\n['loss', 'compile_metrics']\n\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n\n\nFOLD 4:\n\nCarregamento das imagens do fold 4 para treinamento.............!\nNumero de imagens no treinamento: 52401 imagens.\nNumero de imagens na validação: 17433 imagens.\nNumero de imagens no teste: 17502 imagens.\n\nIniciando o treinamento.........................................!\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 254ms/step - categorical_accuracy: 0.6572 - loss: 1.4434 - val_categorical_accuracy: 0.6004 - val_loss: 1.0231\nEpoch 2/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9336 - loss: 0.1782 - val_categorical_accuracy: 0.6245 - val_loss: 1.6422\nEpoch 3/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9742 - loss: 0.0705 - val_categorical_accuracy: 0.6265 - val_loss: 2.2010\nEpoch 4/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9852 - loss: 0.0402 - val_categorical_accuracy: 0.6201 - val_loss: 3.0194\nEpoch 5/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9911 - loss: 0.0248 - val_categorical_accuracy: 0.6013 - val_loss: 3.2730\nEpoch 6/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9921 - loss: 0.0246 - val_categorical_accuracy: 0.6345 - val_loss: 3.3958\nEpoch 7/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9958 - loss: 0.0131 - val_categorical_accuracy: 0.6380 - val_loss: 3.1473\nEpoch 8/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9961 - loss: 0.0118 - val_categorical_accuracy: 0.6214 - val_loss: 4.6360\nEpoch 9/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9973 - loss: 0.0079 - val_categorical_accuracy: 0.6407 - val_loss: 3.1783\nEpoch 10/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9951 - loss: 0.0152 - val_categorical_accuracy: 0.6193 - val_loss: 3.8416\nEpoch 11/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9982 - loss: 0.0058 - val_categorical_accuracy: 0.6258 - val_loss: 4.4327\nEpoch 12/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9981 - loss: 0.0061 - val_categorical_accuracy: 0.6384 - val_loss: 5.2684\nEpoch 13/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9983 - loss: 0.0054 - val_categorical_accuracy: 0.6158 - val_loss: 3.7354\nEpoch 14/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9983 - loss: 0.0054 - val_categorical_accuracy: 0.6160 - val_loss: 4.7335\nEpoch 15/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9984 - loss: 0.0057 - val_categorical_accuracy: 0.6337 - val_loss: 5.4260\nEpoch 16/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9981 - loss: 0.0057 - val_categorical_accuracy: 0.6413 - val_loss: 4.6746\nEpoch 17/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - categorical_accuracy: 0.9980 - loss: 0.0053 - val_categorical_accuracy: 0.6349 - val_loss: 5.2147\nEpoch 18/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9988 - loss: 0.0045 - val_categorical_accuracy: 0.6168 - val_loss: 5.0407\nEpoch 19/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9984 - loss: 0.0051 - val_categorical_accuracy: 0.6371 - val_loss: 5.9789\nEpoch 20/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9992 - loss: 0.0023 - val_categorical_accuracy: 0.6263 - val_loss: 4.5074\nEpoch 21/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9960 - loss: 0.0117 - val_categorical_accuracy: 0.6337 - val_loss: 5.3040\nEpoch 22/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9989 - loss: 0.0040 - val_categorical_accuracy: 0.6228 - val_loss: 5.8174\nEpoch 23/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9994 - loss: 0.0024 - val_categorical_accuracy: 0.6296 - val_loss: 7.7703\nEpoch 24/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 0.9999 - loss: 4.2145e-04 - val_categorical_accuracy: 0.6240 - val_loss: 8.5362\nEpoch 25/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 1.0000 - loss: 9.7981e-05 - val_categorical_accuracy: 0.6232 - val_loss: 8.7785\nEpoch 26/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 1.0000 - loss: 7.8519e-06 - val_categorical_accuracy: 0.6223 - val_loss: 9.0700\nEpoch 27/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 1.0000 - loss: 1.0920e-05 - val_categorical_accuracy: 0.6240 - val_loss: 9.2507\nEpoch 28/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 1.0000 - loss: 9.6750e-06 - val_categorical_accuracy: 0.6244 - val_loss: 9.8516\nEpoch 29/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 1.0000 - loss: 2.1503e-05 - val_categorical_accuracy: 0.6395 - val_loss: 10.6337\nEpoch 30/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 171ms/step - categorical_accuracy: 1.0000 - loss: 1.1796e-05 - val_categorical_accuracy: 0.6358 - val_loss: 10.3272\n\nTestando imagens................................................!\n\n\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - categorical_accuracy: 0.4524 - loss: 11.5599\n['loss', 'compile_metrics']\n\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n\n\nFOLD 5:\n\nCarregamento das imagens do fold 5 para treinamento.............!\nNumero de imagens no treinamento: 52413 imagens.\nNumero de imagens na validação: 17433 imagens.\nNumero de imagens no teste: 17490 imagens.\n\nIniciando o treinamento.........................................!\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 263ms/step - categorical_accuracy: 0.6580 - loss: 0.8376 - val_categorical_accuracy: 0.5210 - val_loss: 1.3324\nEpoch 2/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 176ms/step - categorical_accuracy: 0.9416 - loss: 0.1633 - val_categorical_accuracy: 0.5431 - val_loss: 2.0160\nEpoch 3/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9716 - loss: 0.0789 - val_categorical_accuracy: 0.5563 - val_loss: 2.5555\nEpoch 4/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9825 - loss: 0.0489 - val_categorical_accuracy: 0.5340 - val_loss: 2.7194\nEpoch 5/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9870 - loss: 0.0344 - val_categorical_accuracy: 0.5592 - val_loss: 4.0602\nEpoch 6/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9913 - loss: 0.0252 - val_categorical_accuracy: 0.5672 - val_loss: 3.7028\nEpoch 7/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9930 - loss: 0.0197 - val_categorical_accuracy: 0.5570 - val_loss: 4.0566\nEpoch 8/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9952 - loss: 0.0143 - val_categorical_accuracy: 0.5705 - val_loss: 4.6357\nEpoch 9/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9958 - loss: 0.0141 - val_categorical_accuracy: 0.5540 - val_loss: 4.7341\nEpoch 10/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9962 - loss: 0.0131 - val_categorical_accuracy: 0.6087 - val_loss: 4.4751\nEpoch 11/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9978 - loss: 0.0068 - val_categorical_accuracy: 0.5861 - val_loss: 5.0171\nEpoch 12/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9975 - loss: 0.0085 - val_categorical_accuracy: 0.5846 - val_loss: 4.7231\nEpoch 13/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9967 - loss: 0.0108 - val_categorical_accuracy: 0.5442 - val_loss: 5.1601\nEpoch 14/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9985 - loss: 0.0050 - val_categorical_accuracy: 0.5577 - val_loss: 5.4921\nEpoch 15/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9984 - loss: 0.0047 - val_categorical_accuracy: 0.5781 - val_loss: 5.6788\nEpoch 16/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9974 - loss: 0.0070 - val_categorical_accuracy: 0.5571 - val_loss: 6.3202\nEpoch 17/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9983 - loss: 0.0066 - val_categorical_accuracy: 0.5448 - val_loss: 7.0084\nEpoch 18/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9993 - loss: 0.0028 - val_categorical_accuracy: 0.5774 - val_loss: 5.7268\nEpoch 19/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9987 - loss: 0.0041 - val_categorical_accuracy: 0.6028 - val_loss: 7.4201\nEpoch 20/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9985 - loss: 0.0059 - val_categorical_accuracy: 0.5648 - val_loss: 6.1216\nEpoch 21/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9984 - loss: 0.0053 - val_categorical_accuracy: 0.6000 - val_loss: 6.3713\nEpoch 22/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9985 - loss: 0.0050 - val_categorical_accuracy: 0.5830 - val_loss: 5.3186\nEpoch 23/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9987 - loss: 0.0042 - val_categorical_accuracy: 0.6016 - val_loss: 7.0154\nEpoch 24/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9978 - loss: 0.0071 - val_categorical_accuracy: 0.5613 - val_loss: 5.7172\nEpoch 25/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9988 - loss: 0.0040 - val_categorical_accuracy: 0.5791 - val_loss: 7.6252\nEpoch 26/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9980 - loss: 0.0061 - val_categorical_accuracy: 0.5949 - val_loss: 5.3301\nEpoch 27/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9992 - loss: 0.0025 - val_categorical_accuracy: 0.6170 - val_loss: 8.9384\nEpoch 28/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - categorical_accuracy: 0.9997 - loss: 7.4606e-04 - val_categorical_accuracy: 0.5990 - val_loss: 7.9426\nEpoch 29/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9979 - loss: 0.0083 - val_categorical_accuracy: 0.6034 - val_loss: 6.1385\nEpoch 30/30\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - categorical_accuracy: 0.9989 - loss: 0.0042 - val_categorical_accuracy: 0.5871 - val_loss: 6.1012\n\nTestando imagens................................................!\n\n\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - categorical_accuracy: 0.3694 - loss: 12.5117\n['loss', 'compile_metrics']\n\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Salvamento de Dados","metadata":{}},{"cell_type":"code","source":"#--------------------------------------------------------------------------\n# SALVAMENTO DOS DADOS\n\nprint('\\nSalvando informações da rede......................................!')\n\npath = RESULTS_PATH + f'/{DATASET_TYPE}-resultados_rede-incial-conv2d.txt'\n    \nmatrix_total = np.sum(lst_matrix, axis=0)\naccuracy_total = np.trace(matrix_total)/np.sum(matrix_total)\n    \nlosses=[]\nval_losses=[]\naccuracies=[]\nval_accuracies=[]\n\nfor item in lst_history:\n    \n    history=item.history\n    loss=history['loss']\n    accuracy=history['categorical_accuracy']\n    \n    val_loss=history['val_loss']\n    val_accuracy=history['val_categorical_accuracy']\n    \n    losses.append(sum(loss)/len(loss))\n    accuracies.append(sum(accuracy)/len(accuracy))\n    \n    val_losses.append(sum(val_loss)/len(val_loss))\n    val_accuracies.append(sum(val_accuracy)/len(val_accuracy))\n\nf1=open(path,'w')\nf1.write(f'TREINAMENTO USANDO A REDE INICIAL CATEGORICA COM DADOS EM ARRAYS E DATASET {DATASET_TYPE}\\n')\n\nf1.write('\\nTest Accuracias: '+str(lst_acc)+'\\nTest Losses: '+str(lst_loss))\nf1.write('\\n\\nTest Accuracies Mean: '+str(np.mean(lst_acc)))\n\nf1.write('\\n\\n__________________________________________________________\\n')\n\nf1.write('\\n\\nValid Accuracies: '+str(val_accuracies)+'\\nValid Losses: '+str(val_losses))\nf1.write('\\n\\nValid Accuracies Mean: '+str(np.mean(val_accuracies)))\n\nf1.write('\\n\\n__________________________________________________________\\n')\n\nf1.write('\\nAccuracies from Confusion Matrix: '+str(lst_accuracy))\n\nf1.write('\\n\\nTotal Confusion Matrix: \\n'+str(matrix_total)+'\\n\\n')\nf1.write('\\nTotal Accuracie from Confusion Matrix: '+str(accuracy_total))\n\nf1.write('\\n\\n__________________________________________________________\\n')\n\nf1.write('\\n\\nMetrics for all Folds: \\n\\n')\nfor i in range(len(lst_reports)):\n    f1.write(str(lst_reports[i]))\n    f1.write('\\n\\nTraining Time: '+str(lst_times[i])+'\\nAUC: '+str(lst_AUC[i]))\n    f1.write('\\n\\nAcurácia: ' + str(lst_accuracy[i]))\n    f1.write('\\n\\nMatriz de Confusao: \\n'+str(lst_matrix[i])+'\\n\\n__________________________________________________________\\n')\nf1.close()","metadata":{"execution":{"iopub.status.busy":"2024-06-25T22:47:29.820012Z","iopub.execute_input":"2024-06-25T22:47:29.82035Z","iopub.status.idle":"2024-06-25T22:47:29.838453Z","shell.execute_reply.started":"2024-06-25T22:47:29.820322Z","shell.execute_reply":"2024-06-25T22:47:29.837286Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\nSalvando informações da rede......................................!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Zipando pasta com resultados\nimport zipfile\n\ndef compactar_pasta(pasta, nome_arquivo_zip):\n    with zipfile.ZipFile(nome_arquivo_zip, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n        for root, _, files in os.walk(pasta):\n            for arquivo in files:\n                caminho_completo = os.path.join(root, arquivo)\n                zip_file.write(caminho_completo, os.path.relpath(caminho_completo, pasta))\n\nnome_arquivo_zip = f'{DATASET_TYPE}-results.zip'\ncompactar_pasta(RESULTS_PATH, nome_arquivo_zip)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T22:47:29.840099Z","iopub.execute_input":"2024-06-25T22:47:29.840557Z","iopub.status.idle":"2024-06-25T22:48:17.590484Z","shell.execute_reply.started":"2024-06-25T22:47:29.840516Z","shell.execute_reply":"2024-06-25T22:48:17.589515Z"},"trusted":true},"execution_count":12,"outputs":[]}]}